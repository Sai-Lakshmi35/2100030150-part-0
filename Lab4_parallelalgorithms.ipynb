{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJq9tLYv1AZh2owSIXF4ba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-Lakshmi35/2100030150-part-0/blob/main/Lab4_parallelalgorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ggq01C07dG6",
        "outputId": "6f1c7554-9d8a-4154-cf44-a9b8a01bce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMUXWtqa8gP2",
        "outputId": "85aef0f4-b2d3-4100-f8dc-52f98bdd31c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-cpckc8xi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-cpckc8xi\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5cd225851b7638f3f6d55a19328295f16c014079\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.0.3-py3-none-any.whl size=7432 sha256=ad99cf1e6175f37f13398802e9e82d42885745e385f9d1c2ce678f3d359f3a95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-klc25qyw/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lL7_qdB8yCD",
        "outputId": "2b1cf6f3-c609-4bb8-eaa7-99929d9edab0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0KtGY0q83Za",
        "outputId": "82016f79-c721-4211-a52d-3ae5c11e1b4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source files will be saved in \"/tmp/tmp8lgwsbdp\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "__global__ void hello(){\n",
        "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "int main(){\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UURg1xv-9Sl8",
        "outputId": "7eb01821-e235-4bea-9df6-13495370c7fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block: 0, thread: 0\n",
            "Hello from block: 0, thread: 1\n",
            "Hello from block: 1, thread: 0\n",
            "Hello from block: 1, thread: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <iostream>\n",
        "#define THREADS 256\n",
        "// function to add the elements of an arrays\n",
        "__global__\n",
        "void sumx(int n, float *x, float *result)\n",
        "{\n",
        "   //We need a shared array to store all intermediary calculations\n",
        "  __shared__ float intermedsum[THREADS];\n",
        "  int index = threadIdx.x;\n",
        "  int numthrds = blockDim.x;\n",
        "  if (index == 0){\n",
        "  *result=0.0f;\n",
        "  }\n",
        "  __syncthreads();          //we need to wait till all threads are done\n",
        "  float localsum=0.0f; //initialize the local sum to 0\n",
        "  int l=n/numthrds; // define the length of x that each thread has to solve\n",
        "  for (int i = (index*l); i < ((index+1)*l); i++)\n",
        "    {\n",
        "      localsum += x[i];\n",
        "    }\n",
        "  intermedsum[index]=localsum; //store the local sum\n",
        "  __syncthreads();          //we need to wait till all threads are done\n",
        "//now we can start the tree\n",
        "  int level=2; //indicates at which level of the tree we are starting from bottom\n",
        "  while(level<(numthrds+1))  // stop when we're higher than max number of threads\n",
        "    {\n",
        "      int stride=level/2; //stride between a thread at this level and the next thread at the previous level\n",
        "\n",
        "      if ((index % level)==0) //check if the thread is still used at that level\n",
        "\t{\n",
        "\t  intermedsum[index]+=intermedsum[index+stride];\n",
        "\t}\n",
        "      level=2*level; //go to next level\n",
        "      __syncthreads();        //but first again wait till all threads are done\n",
        "    }\n",
        "  //at the end of this loop only thread0 should have saved the final sum in intermedsum[0]\n",
        "  if (index==0)\n",
        "    {\n",
        "      *result=intermedsum[0]; //so we can finally save it!\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "int N = 1<<20; // 1M elements\n",
        " float *x;\n",
        " cudaMallocManaged(&x, N*sizeof(float));\n",
        " float *result;\n",
        " cudaMallocManaged(&result,sizeof(float));\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "  }\n",
        "  *result=0.0f;\n",
        "  clock_t start;\n",
        "  clock_t end;\n",
        "  // Prefetch the data to the GPU\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "  cudaMemPrefetchAsync(x, N*sizeof(float), device, NULL);\n",
        "  //Let us time the execution\n",
        "  start=clock();\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  sumx<<<1,THREADS>>>(N, x,result);\n",
        "  cudaDeviceSynchronize();\n",
        "  end=clock();\n",
        "  printf( \"result: %f \\n\", *result);\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float Error = (float) N-*result;\n",
        "  printf( \"Max error: %f \\n\", Error);\n",
        "  printf(\"Time for kernel=%f\\n\", (double) (end-start)/ CLOCKS_PER_SEC);\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(result);\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boAr1EkH9vgV",
        "outputId": "9a8063e0-2f0d-4dce-ea4a-116832b11799"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result: 1048576.000000 \n",
            "Max error: 0.000000 \n",
            "Time for kernel=0.075530\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "__global__ void scan(int *d_in,int *d_out,int n)\n",
        "{\n",
        "    extern __shared__ int sdata[];\n",
        "    int i;\n",
        "    int tid = threadIdx.x;\n",
        "    sdata[tid] = d_in[tid];\n",
        "    for (i = 1; i <n; i <<= 1)\n",
        "     {\n",
        "\n",
        "        if (tid>=i)\n",
        "         {\n",
        "            sdata[tid] +=sdata[tid-i];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    d_out[tid] = sdata[tid];\n",
        "     __syncthreads();\n",
        " }\n",
        "\n",
        "int main()\n",
        " {\n",
        "\n",
        "    int h_in[16],h_out[16];\n",
        "     int i;\n",
        "     for (i = 0; i < 16; i++)\n",
        "        h_in[i] = 2*i+1;\n",
        "    for (i = 0; i < 16; i++)\n",
        "        printf(\"%d \", h_in[i]);\n",
        "   int *d_in;\n",
        "   int *d_out;\n",
        "   cudaMalloc((void**)&d_in, sizeof(int)* 16);\n",
        "   cudaMalloc((void**)&d_out, sizeof(int)* 16);\n",
        "   cudaMemcpy(d_in, h_in, sizeof(int) * 16, cudaMemcpyHostToDevice);\n",
        "   scan <<<1, 16 >>>(d_in,d_out, 16);\n",
        "   cudaMemcpy(h_out, d_out, sizeof(int) * 16, cudaMemcpyDeviceToHost);\n",
        "   for (i = 0; i < 16; i++)\n",
        "      printf(\"%d \", h_out[i]);\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQwkKu4uAQTt",
        "outputId": "db7323e7-f4de-4d9a-feda-4f29bd63171a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "__global__ void addKernel(int* c, const int* a, const int* b, int size) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "// Helper function for using CUDA to add vectors in parallel.\n",
        "void addWithCuda(int* c, const int* a, const int* b, int size) {\n",
        "    int* dev_a = NULL;\n",
        "    int* dev_b = NULL;\n",
        "    int* dev_c = NULL;\n",
        "    // Allocate GPU buffers for three vectors (two input, one output)\n",
        "    cudaMalloc((void**)&dev_c, size * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_a, size * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, size * sizeof(int));\n",
        "    // Copy input vectors from host memory to GPU buffers.\n",
        "    cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    // Launch a kernel on the GPU with one thread for each element.\n",
        "    // 2 is number of computational blocks and (size + 1) / 2 is a number of threads in a block\n",
        "    addKernel<<<2, (size + 1) / 2>>>(dev_c, dev_a, dev_b, size);\n",
        "    // cudaDeviceSynchronize waits for the kernel to finish, and returns\n",
        "    // any errors encountered during the launch.\n",
        "    cudaDeviceSynchronize();\n",
        "    // Copy output vector from GPU buffer to host memory.\n",
        "    cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaFree(dev_c);\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "}\n",
        "int main(int argc, char** argv) {\n",
        "    const int arraySize = 5;\n",
        "    const int a[arraySize] = {  1,  2,  3,  4,  5 };\n",
        "    const int b[arraySize] = { 10, 20, 30, 40, 50 };\n",
        "    int c[arraySize] = { 0 };\n",
        "    addWithCuda(c, a, b, arraySize);\n",
        "    printf(\"{1, 2, 3, 4, 5} + {10, 20, 30, 40, 50} = {%d, %d, %d, %d, %d}\\n\", c[0], c[1], c[2], c[3], c[4]);\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUfG5fJYAnWK",
        "outputId": "ab2c9aaa-4d44-4a50-ed6b-d12c871acef0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2, 3, 4, 5} + {10, 20, 30, 40, 50} = {11, 22, 33, 44, 55}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "__global__ void isprime(int *test_number, int *boolprime){\n",
        "  int dividedby = threadIdx.x + blockIdx.x * blockDim.x; /*Compute the number wich the test_number will be divided by for each threards.*/\n",
        "  if(dividedby > 1 && dividedby < *test_number){  // look to see if it's fine to do to test\n",
        "    if(*test_number % dividedby == 0){*boolprime = 0;}\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(void){\n",
        "  printf(\"Finding prime numbers using CUDA\\n\");\n",
        "  int primelesserthan = 1000;  // Will test every number before\n",
        "  int maxthreads = 1024;\n",
        "  int Nb_blocks;\n",
        "  int Nb_threads;\n",
        "  int test_number, boolprime;  // host copies of test_number\n",
        "  int *d_test_number, *d_boolprime;   // device copies of test_number\n",
        "  cudaMalloc((void **)&d_test_number, sizeof(test_number)); // Allocate space for device copies of test_number\n",
        "  cudaMalloc((void **)&d_boolprime, sizeof(boolprime));\n",
        "  for(test_number = 2; test_number < primelesserthan; test_number++){\n",
        "    boolprime = 1; //reset boolprime\n",
        "    cudaMemcpy(d_test_number, &test_number, sizeof(test_number), cudaMemcpyHostToDevice);  // Copy data to device\n",
        "    cudaMemcpy(d_boolprime, &boolprime, sizeof(boolprime), cudaMemcpyHostToDevice);\n",
        "    // find the rigth number of blocks and threads\n",
        "    if(test_number/maxthreads == 0){Nb_blocks = 1; Nb_threads = test_number;}\n",
        "    else{Nb_blocks = test_number/maxthreads; Nb_threads = test_number%maxthreads;}\n",
        "    isprime<<<Nb_blocks,Nb_threads>>>(d_test_number, d_boolprime);   // Launch add() kernel on GPU\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemcpy(&boolprime,d_boolprime,sizeof(boolprime),cudaMemcpyDeviceToHost);\n",
        "    // if(boolprime == 0){printf(\"%d is not prime\\n\",test_number);}\n",
        "    // else{printf(\"%d is prime\\n\",test_number);}\n",
        "    if(boolprime == 1){printf(\"%d is prime\\n\",test_number);}\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIVmdWVcDaD6",
        "outputId": "64fe17ef-8c49-4334-c453-a1bc64930705"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding prime numbers using CUDA\n",
            "2 is prime\n",
            "3 is prime\n",
            "5 is prime\n",
            "7 is prime\n",
            "11 is prime\n",
            "13 is prime\n",
            "17 is prime\n",
            "19 is prime\n",
            "23 is prime\n",
            "29 is prime\n",
            "31 is prime\n",
            "37 is prime\n",
            "41 is prime\n",
            "43 is prime\n",
            "47 is prime\n",
            "53 is prime\n",
            "59 is prime\n",
            "61 is prime\n",
            "67 is prime\n",
            "71 is prime\n",
            "73 is prime\n",
            "79 is prime\n",
            "83 is prime\n",
            "89 is prime\n",
            "97 is prime\n",
            "101 is prime\n",
            "103 is prime\n",
            "107 is prime\n",
            "109 is prime\n",
            "113 is prime\n",
            "127 is prime\n",
            "131 is prime\n",
            "137 is prime\n",
            "139 is prime\n",
            "149 is prime\n",
            "151 is prime\n",
            "157 is prime\n",
            "163 is prime\n",
            "167 is prime\n",
            "173 is prime\n",
            "179 is prime\n",
            "181 is prime\n",
            "191 is prime\n",
            "193 is prime\n",
            "197 is prime\n",
            "199 is prime\n",
            "211 is prime\n",
            "223 is prime\n",
            "227 is prime\n",
            "229 is prime\n",
            "233 is prime\n",
            "239 is prime\n",
            "241 is prime\n",
            "251 is prime\n",
            "257 is prime\n",
            "263 is prime\n",
            "269 is prime\n",
            "271 is prime\n",
            "277 is prime\n",
            "281 is prime\n",
            "283 is prime\n",
            "293 is prime\n",
            "307 is prime\n",
            "311 is prime\n",
            "313 is prime\n",
            "317 is prime\n",
            "331 is prime\n",
            "337 is prime\n",
            "347 is prime\n",
            "349 is prime\n",
            "353 is prime\n",
            "359 is prime\n",
            "367 is prime\n",
            "373 is prime\n",
            "379 is prime\n",
            "383 is prime\n",
            "389 is prime\n",
            "397 is prime\n",
            "401 is prime\n",
            "409 is prime\n",
            "419 is prime\n",
            "421 is prime\n",
            "431 is prime\n",
            "433 is prime\n",
            "439 is prime\n",
            "443 is prime\n",
            "449 is prime\n",
            "457 is prime\n",
            "461 is prime\n",
            "463 is prime\n",
            "467 is prime\n",
            "479 is prime\n",
            "487 is prime\n",
            "491 is prime\n",
            "499 is prime\n",
            "503 is prime\n",
            "509 is prime\n",
            "521 is prime\n",
            "523 is prime\n",
            "541 is prime\n",
            "547 is prime\n",
            "557 is prime\n",
            "563 is prime\n",
            "569 is prime\n",
            "571 is prime\n",
            "577 is prime\n",
            "587 is prime\n",
            "593 is prime\n",
            "599 is prime\n",
            "601 is prime\n",
            "607 is prime\n",
            "613 is prime\n",
            "617 is prime\n",
            "619 is prime\n",
            "631 is prime\n",
            "641 is prime\n",
            "643 is prime\n",
            "647 is prime\n",
            "653 is prime\n",
            "659 is prime\n",
            "661 is prime\n",
            "673 is prime\n",
            "677 is prime\n",
            "683 is prime\n",
            "691 is prime\n",
            "701 is prime\n",
            "709 is prime\n",
            "719 is prime\n",
            "727 is prime\n",
            "733 is prime\n",
            "739 is prime\n",
            "743 is prime\n",
            "751 is prime\n",
            "757 is prime\n",
            "761 is prime\n",
            "769 is prime\n",
            "773 is prime\n",
            "787 is prime\n",
            "797 is prime\n",
            "809 is prime\n",
            "811 is prime\n",
            "821 is prime\n",
            "823 is prime\n",
            "827 is prime\n",
            "829 is prime\n",
            "839 is prime\n",
            "853 is prime\n",
            "857 is prime\n",
            "859 is prime\n",
            "863 is prime\n",
            "877 is prime\n",
            "881 is prime\n",
            "883 is prime\n",
            "887 is prime\n",
            "907 is prime\n",
            "911 is prime\n",
            "919 is prime\n",
            "929 is prime\n",
            "937 is prime\n",
            "941 is prime\n",
            "947 is prime\n",
            "953 is prime\n",
            "967 is prime\n",
            "971 is prime\n",
            "977 is prime\n",
            "983 is prime\n",
            "991 is prime\n",
            "997 is prime\n",
            "\n"
          ]
        }
      ]
    }
  ]
}